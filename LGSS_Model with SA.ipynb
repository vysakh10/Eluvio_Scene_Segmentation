{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, MaxPool3D, Conv2D, LSTM\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name_tr = 'Train'\n",
    "f_name_cv = 'CV'\n",
    "f_name_te = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(f_name):   \n",
    "    lst = []\n",
    "    for i in tqdm(os.listdir(f_name)):\n",
    "        with open(f_name + '/' + i, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        t_place = tf.reshape(data['place'], (1, -1, 2048))\n",
    "        t_cast = tf.reshape(data['cast'], (1, -1, 512))\n",
    "        t_action = tf.reshape(data['action'], (1, -1, 512))\n",
    "        t_audio = tf.reshape(data['audio'], (1, -1, 512))\n",
    "        t_labels = tf.reshape(data['labels'], (1, -1, 1))\n",
    "        \n",
    "        d_tuple = (t_place, t_cast, t_action, t_audio, t_labels)\n",
    "        lst.append(d_tuple)\n",
    "        \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:12<00:00,  4.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.75it/s]\n"
     ]
    }
   ],
   "source": [
    "data_train = data_loader(f_name_tr)\n",
    "data_cv = data_loader(f_name_cv)\n",
    "data_test = data_loader(f_name_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1144, 2048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights\"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead_Self_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHead_Self_Attention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)  \n",
    "        v = self.wv(v)  \n",
    "\n",
    "        q = self.split_heads(q, batch_size)  \n",
    "        k = self.split_heads(k, batch_size)  \n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cosine_similarity(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(cosine_similarity, self).__init__()\n",
    "        self.conv1 = Conv2D(124, (4), data_format='channels_last', padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        if x.shape[1] % 2 == 0:\n",
    "            x1, x2 = tf.split(x, 2, 1)\n",
    "        else:\n",
    "            x = x[:, 1:, :]\n",
    "            x1, x2 = tf.split(x, 2, 1)\n",
    "        \n",
    "        x1 = tf.reshape(x1, (-1, 1, x1.shape[1], x1.shape[2]))\n",
    "        cv1 = self.conv1(x1)\n",
    "        \n",
    "        x2 = tf.reshape(x2, (-1, 1, x2.shape[1], x2.shape[2]))\n",
    "        cv2 = self.conv1(x2)\n",
    "        \n",
    "        cs = tf.keras.layers.dot( [cv1, cv2],axes=2)\n",
    "        cs = tf.reshape(cs, (-1, 1, cs.shape[2], cs.shape[4]))\n",
    "        cs = tf.add(cs[:,:,2], cs[:,:,3])\n",
    "        \n",
    "        return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNet_place(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BNet_place, self).__init__()\n",
    "        self.conv1 = Conv2D(128, 4, data_format='channels_last', padding='same')        \n",
    "        self.maxpool = MaxPool3D((1,1,5),1, data_format = 'channels_last')\n",
    "        self.cos = cosine_similarity()\n",
    "        self.lstm = LSTM(128, return_sequences=True)\n",
    "        self.dense1 = Dense(64, activation='relu', kernel_initializer='he_normal')\n",
    "        self.dense2 = Dense(1, activation='sigmoid')\n",
    "        self.self_attention = MultiHead_Self_Attention(d_model=128, num_heads=4)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        x1 = tf.reshape(x, (-1, 1, x.shape[1], x.shape[2]))  \n",
    "        cv1 = self.conv1(x1)        \n",
    "        cv1 = tf.reshape(cv1, (-1, 1,1, cv1.shape[3], cv1.shape[2]))\n",
    "        \n",
    "        m1 = self.maxpool(cv1)\n",
    "        m1 = tf.reshape(m1, (-1, m1.shape[4], m1.shape[3]))        \n",
    "        cosine_sim = self.cos(x)\n",
    "        \n",
    "        add = tf.add(m1, cosine_sim)\n",
    "\n",
    "        s_att, _ = self.self_attention(add,add,add,None)\n",
    "\n",
    "        fc1 = self.dense1(s_att)\n",
    "        fc2 = self.dense2(fc1)\n",
    "        print('FC2: ', fc2.shape)\n",
    "\n",
    "        return fc2[:,:-1,:]\n",
    "    \n",
    "class BNet(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BNet, self).__init__()\n",
    "        self.conv1 = Conv2D(128, 4, data_format='channels_last', padding='same')        \n",
    "        self.maxpool = MaxPool3D((1,1,5),1, data_format = 'channels_last')\n",
    "        self.cos = cosine_similarity()\n",
    "        self.lstm = LSTM(128, return_sequences=True)\n",
    "        self.dense1 = Dense(64, activation='relu', kernel_initializer='he_normal')\n",
    "        self.dense2 = Dense(1, activation='sigmoid')\n",
    "        self.self_attention = MultiHead_Self_Attention(d_model=128, num_heads=4)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "\n",
    "        x1 = tf.reshape(x, (-1, 1, x.shape[1], x.shape[2]))\n",
    "        cv1 = self.conv1(x1)\n",
    "        \n",
    "        cv1 = tf.reshape(cv1, (-1, 1,1, cv1.shape[3], cv1.shape[2]))\n",
    "        \n",
    "        m1 = self.maxpool(cv1)\n",
    "        m1 = tf.reshape(m1, (-1, m1.shape[4], m1.shape[3]))\n",
    "        \n",
    "        cosine_sim = self.cos(x)\n",
    "        \n",
    "        add = tf.add(m1, cosine_sim)\n",
    "\n",
    "        s_att, _ = self.self_attention(add,add,add,None)\n",
    "        \n",
    "        fc1 = self.dense1(s_att)\n",
    "        fc2 = self.dense2(fc1)\n",
    "        \n",
    "        return fc2[:,:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGSS(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(LGSS, self).__init__()\n",
    "        self.bnet_place = BNet_place()\n",
    "        self.bnet_cast = BNet()\n",
    "        self.bnet_action = BNet()\n",
    "        self.bnet_audio = BNet()\n",
    "    def call(self, place_feat, cast_feat, action_feat, audio_feat):\n",
    "        \n",
    "        output = 0\n",
    "       # print('\\nPlace Feature: ', place_feat.shape)\n",
    "        p_bnet = self.bnet_place(place_feat)\n",
    "        output += 0.5*p_bnet\n",
    "       # print('\\nCast Feature: ', cast_feat.shape)\n",
    "        c_bnet = self.bnet_cast(cast_feat)\n",
    "        output += 0.2*c_bnet\n",
    "       # print('\\nAction Feature: ',action_feat.shape)\n",
    "        ac_bnet = self.bnet_action(action_feat)\n",
    "        output += 0.2*ac_bnet\n",
    "       # print('\\nAudio Feature: ', audio_feat.shape)\n",
    "        a_bnet = self.bnet_audio(audio_feat)\n",
    "        output += 0.1*a_bnet\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Local_to_Global_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Local_to_Global_Model, self).__init__()\n",
    "        self.lgss = LGSS()\n",
    "    \n",
    "    def call(self, data):\n",
    "        place_features = data[0]\n",
    "        cast_features = data[1]\n",
    "        action_features = data[2]\n",
    "        audio_features = data[3]\n",
    "        \n",
    "        output = self.lgss(place_features, cast_features, action_features, audio_features)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGSS_model = Local_to_Global_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "LGSS_model.compile(optimizer=optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "epoch_train_loss = []\n",
    "epoch_cv_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1244, 2048])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[3][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n",
      "Add:  (None, 1101, 124)\n",
      "S_att:  (None, None, 128)\n",
      "FC2:  (None, None, 1)\n",
      "Add:  (None, 1101, 124)\n",
      "S_att:  (None, None, 128)\n",
      "FC2:  (None, None, 1)\n",
      "Add:  (None, 1101, 124)\n",
      "S_att:  (None, None, 128)\n",
      "FC2:  (None, None, 1)\n",
      "Add:  (None, 1101, 124)\n",
      "S_att:  (None, None, 128)\n",
      "FC2:  (None, None, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "Add:  (1, 1101, 124)\n",
      "S_att:  (1, 1101, 128)\n",
      "FC2:  (1, 1101, 1)\n",
      "1\n",
      "Add:  (1, 1144, 124)\n",
      "S_att:  (1, 1144, 128)\n",
      "FC2:  (1, 1144, 1)\n",
      "Add:  (1, 1144, 124)\n",
      "S_att:  (1, 1144, 128)\n",
      "FC2:  (1, 1144, 1)\n",
      "Add:  (1, 1144, 124)\n",
      "S_att:  (1, 1144, 128)\n",
      "FC2:  (1, 1144, 1)\n",
      "Add:  (1, 1144, 124)\n",
      "S_att:  (1, 1144, 128)\n",
      "FC2:  (1, 1144, 1)\n",
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py:305 train_on_batch  *\n        outs, total_loss, output_losses, masks = (\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py:253 _process_single_batch\n        training=training))\n    <ipython-input-36-3fe5e39cc309>:15 call  *\n        output = self.lgss(place_features, cast_features, action_features, audio_features)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-11-46b80cbdf15b>:12 call  *\n        p_bnet = self.bnet_place(place_feat)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-34-4c7c333ecb5f>:15 call  *\n        x1 = tf.reshape(x, (-1, 1, x.shape[1], x.shape[2]))  # hereeeeeeeeeee\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:193 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py:7443 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:471 _apply_op_helper\n        raise err\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:468 _apply_op_helper\n        preferred_dtype=default_dtype)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1314 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:317 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:258 constant\n        allow_broadcast=True)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:296 _constant_impl\n        allow_broadcast=allow_broadcast))\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py:547 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (-1, 1, None, 2048). Consider casting elements to a supported type.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d822e7b51b66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mc_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mt_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mLGSS_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mc_\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1076\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m           standalone=True)\n\u001b[0m\u001b[0;32m   1079\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m   1080\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[0;32m    431\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2360\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2362\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2698\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 2700\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2630\u001b[0m         relaxed_arg_shapes)\n\u001b[0;32m   2631\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 2632\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py:305 train_on_batch  *\n        outs, total_loss, output_losses, masks = (\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py:253 _process_single_batch\n        training=training))\n    <ipython-input-36-3fe5e39cc309>:15 call  *\n        output = self.lgss(place_features, cast_features, action_features, audio_features)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-11-46b80cbdf15b>:12 call  *\n        p_bnet = self.bnet_place(place_feat)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-34-4c7c333ecb5f>:15 call  *\n        x1 = tf.reshape(x, (-1, 1, x.shape[1], x.shape[2]))  # hereeeeeeeeeee\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:193 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py:7443 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:471 _apply_op_helper\n        raise err\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:468 _apply_op_helper\n        preferred_dtype=default_dtype)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1314 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:317 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:258 constant\n        allow_broadcast=True)\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:296 _constant_impl\n        allow_broadcast=allow_broadcast))\n    D:\\Anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py:547 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (-1, 1, None, 2048). Consider casting elements to a supported type.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print('EPOCH: ', epoch+1)\n",
    "    start = time.time()\n",
    "    t_loss = 0\n",
    "    c_loss = 0\n",
    "    c_ = 0\n",
    "    for i in range(len(data_train)):\n",
    "        t_loss += LGSS_model.train_on_batch(data_train[i][:4], data_train[i][4])\n",
    "        c_+=1\n",
    "        print(c_)\n",
    "    train_loss = t_loss/len(data_train)\n",
    "\n",
    "    for i in range(len(data_cv)):\n",
    "        c_loss += LGSS_model.test_on_batch(data_cv[i][:4], data_cv[i][4])\n",
    "    cv_loss = c_loss/len(data_cv)\n",
    "\n",
    "    epoch_train_loss.append(train_loss)\n",
    "    epoch_cv_loss.append(cv_loss)\n",
    "\n",
    "    print('Training Loss: {},  Validation Loss: {}'.format(train_loss, cv_loss))\n",
    "    print('Time Taken for this Epoch : {} sec'.format(time.time()-start))   \n",
    "    LGSS_model.save_weights('Weights_Model2/epoch_'+ str(epoch+1) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 4 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "LGSS_model.fit(data_train[:4], data_train[4], batch_size=1, epochs=100, verbose=1, \n",
    "               validation_data=(data_cv[:4], data_cv[4]),\n",
    "               callbacks=[AUC, checkpoint, lr_schedule, early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0] *",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
